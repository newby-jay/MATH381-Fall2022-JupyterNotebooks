{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Rules\n",
    "  1. You can use your own notes and any class materials posted eClass, including Jupyter notebooks and anything else posted or linked to in eClass (however, see 4 below)\n",
    "  2. You cannot use any external internet sources (e.g., Google, Wikipedia, StackExchange, etc)\n",
    "  3. You can use your own books as long as they are paper or PDF\n",
    "  4. You cannot use any sort of computer search functionality (internet or otherwise)\n",
    "  5. You must work alone for this exam\n",
    "  6. You may use any theorems proved in class\n",
    "  7. Your answers do not need to be rigorous proofs, but try to be precise\n",
    "  \n",
    "  \n",
    " ## You must turn in your exam before midnight on Saturday (Oct 8th)\n",
    " ### (Even if you start it during the day on Saturday.)\n",
    " \n",
    " -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "Let $x_0, \\ldots, x_n \\in [a, b]$, and let $f$ be sufficiently smooth on $[a, b]$ (i.e., $f\\in C^{n+1}[a, b]$). Suppose that $\\hat{p}(x)$ is a polynomial of degree at most $n$ satisfying $\\vert f(x_i) - \\hat{p}(x_i)\\vert < \\epsilon$ for $i=0,\\ldots, n$. Show that \n",
    "$$ \\vert f(x) - \\hat{p}(x)\\vert \\leq \\frac{\\Vert f^{(n+1)} \\Vert_{\\infty}}{(n+1)!}\\prod_{i=0}^n \\vert x - x_i \\vert + \\kappa \\epsilon $$\n",
    "for all $x\\in [a, b]$, in which $\\kappa$ is the condition number (Lebesgue constant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "Let $p(x)$ be the polynomial of degree at most $n$ that interpolates $f$ at $x_i$, $i=0,\\ldots n$. We know this polynomial exists and is unique by the existence uniqueness theorem. Since $p(x_i) = f(x_i)$ it follows that \n",
    "$$\\vert f(x_i) - \\hat{p}(x_i)\\vert \n",
    "= \\vert f(x_i) - p(x_i) - (\\hat{p}(x_i) - p(x_i)) \\vert \n",
    "= \\vert \\hat{p}(x_i) - p(x_i)\\vert\n",
    "< \\epsilon. $$\n",
    "\n",
    "From the above inequality, we can use the stability theorem given in lecture to obtain the bound\n",
    "$$\\vert \\hat{p}(x) - p(x)\\vert < \\kappa \\epsilon ,$$\n",
    "for all $x\\in [a, b]$.\n",
    "\n",
    "From the interpolation accuracy theorem given in lecture, we have that\n",
    "$$ \\vert f(x) - p(x)\\vert \\leq \\frac{\\Vert f^{(n+1)} \\Vert_{\\infty}}{(n+1)!}\\prod_{i=0}^n \\vert x - x_i \\vert,$$\n",
    "for all $x\\in [a, b]$.\n",
    "\n",
    "Finally, from the triangle inequality we have\n",
    "$$\\vert f(x) - \\hat{p}(x)\\vert \n",
    "= \\vert f(x) + p(x) - (\\hat{p}(x) - p(x))\\vert \n",
    "< \\vert \\hat{p}(x) - p(x)\\vert + \\vert f(x) - p(x)\\vert.\n",
    "$$\n",
    "\n",
    "Combining these three inequalities yields the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "Consider the series\n",
    "$$ S_N = \\sum_{n=1}^{N} \\frac{1}{n}.$$\n",
    "\n",
    "# A\n",
    "Show that the limit \n",
    "$$ \\lim_{N\\to \\infty} S_N = \\infty .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "It suffices to apply an integral test (which also helps us with part D) since the terms $1/n$ are monotonically decreasing. We can bound the partial sums from below with\n",
    "$$f(N) = \\int_{1}^{N}\\frac{1}{x}dx < \\sum_{n=1}^{N} \\frac{1}{n}. $$\n",
    "Since $f(x) = \\log(x) \\to \\infty $ as $x\\to \\infty$, the series diverges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B\n",
    "Explain why summing the series in finite precision floating point arithmetic converges after a finite number of terms; i.e.,\n",
    "$$ \\sum_{n=1}^{\\infty} \\frac{1}{{\\rm fl}(n)} = L < \\infty.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "The set of floating point numbers (either 32bit and 64bit) has a finite number of elements. It follows that there is a largest floating point number. Any real number that is larger than the largest floating point number is given the value of `inf` (called overflow). The corresponding value of `1/inf` is considered to be zero. Hence, there exists an $N>0$ such that ${\\rm fl}(\\frac{1}{{\\rm fl}(n)}) = 0$ for all $n > N$. The sequence of partial sums is non decreasing. We must therefore have a finite limit as $n\\to \\infty$ since $S_n \\leq S_N$ for all $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C\n",
    "Try to predict the number of terms $N$ after which the partial sum $S_N$ will cease to change for\n",
    "  1. 32 bit floating point numbers\n",
    "  2. 64 bit floating point numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "The question only asks you to **try** to predict the value. I gave full marks for any reasonable guess based on facts about the floating point number system. An allowable answer can be based on the largest floating point number even though this turns out to be a bad guess. Since the true cause of convergence is rounding error (i.e., from ${\\rm fl}(S_{n-1} + \\frac{1}{n})$) a better guess would be $1/\\varepsilon$, where $\\varepsilon$ is the rounding unit. The rounding unit is approximately $10^{-8}$ and $10^{-16}$ for `float32` and `float64`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D\n",
    "Confirm your prediction from part C numerically. \n",
    "\n",
    "*Hint: This should just require a simple `for` loop and an `if` statement. Use the `float32()` function to compute the sum in 32 bit float (make sure you do this correctly). For float64, you might not want to compute every single term in the sum, unless you are happy to potentially wait a long time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "In part C, you might have formulated a bad guess based on an incorrect reason for convergence of the sum. The cause of numerical convergence of the sum is due to rounding error from ${\\rm fl}({\\rm fl}(S_{n-1}) + {\\rm fl}(\\frac{1}{{\\rm fl}(n)}))$. As discussed in an example during lecture, if we add a very large floating point number $L$ and a much smaller floating point number $s$, we have ${\\rm fl}(L + s) = L$. This is due to the finite number of digits in the mantissa, which determines the rounding unit $\\varepsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2097152\n"
     ]
    }
   ],
   "source": [
    "## The float32 sum can be computed directly\n",
    "Sn = float32(0)\n",
    "for n in arange(1, 10**7):\n",
    "    y = Sn + float32(1)/float32(n)\n",
    "    if absolute(Sn - y) == 0:\n",
    "        break\n",
    "    Sn = y\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## float64 case\n",
    "I am not taking off any points if you couldn't think of a way to \"short cut\" the sum for float64. Since $S_n$ grows like $\\log(n)$, we can approximate. Let us assume that $S_n \\sim C + \\log(n)$, $n\\to \\infty$, for some constant $C$.\n",
    "### We will first approximate the constant\n",
    "**Note: the constant probably does not affect the answer, but we will include it anyway since it is easy to approximate. By the way, $C$ should be Euler's constant $\\gamma$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577215714898955\n"
     ]
    }
   ],
   "source": [
    "S0 = 0.\n",
    "for n0 in arange(1, 10**7):\n",
    "    S0 += 1./n0\n",
    "\n",
    "## we will restart the sum at a very large number n1\n",
    "## S0 ~ C + log(n0) =>  C ~ S0 - log(n0)\n",
    "C = S0 - log(n0)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140737488355328.0\n"
     ]
    }
   ],
   "source": [
    "guess = 1/finfo(float64).eps/32\n",
    "print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281474978355328.0\n"
     ]
    }
   ],
   "source": [
    "## this should yield an approximation that has around 8 correct digits\n",
    "n1 = around(guess)\n",
    "n = n1\n",
    "for _ in arange(1e8):\n",
    "    n += 1e7\n",
    "    Sn = C + log(n) ## approximate\n",
    "    y = Sn + 1./n\n",
    "    if absolute(Sn - y) == 0:\n",
    "        break\n",
    "    \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281474976710657.0\n"
     ]
    }
   ],
   "source": [
    "## this should yield the (possibly exact) answer\n",
    "n2 = n - 1e7\n",
    "n = n2\n",
    "for _ in arange(1e7):\n",
    "    n += 1\n",
    "    Sn = C + log(n) ## approximate\n",
    "    y = Sn + 1./n\n",
    "    if absolute(Sn - y) == 0:\n",
    "        break\n",
    "    \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "Suppose we are constructing a numerical library for early computers. We wan to devise an efficient algorithm for computing square roots. We can only use the basic arithmetic operations ($*,/,+,-$). Newton's method can be used to find the square root of a positive number $a>0$. \n",
    "\n",
    "# A\n",
    "Formulate the computation of $x = \\sqrt{a}$ as a root finding problem. Derive a fixed point iteration using Newton's method. (Your iteration should only use the basic arithmetic operations $*,/,+,-$.) Show that in this case, we can expect the Newton iteration to converges quadratically for any $a>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "Let $f(x) = x^2 - a$. Clearly $f(x) = 0$ implies that $x = \\pm\\sqrt{a}$, and we can choose the positive solution. Newton's method is \n",
    "$$ x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}.$$\n",
    "In our case, we have that $f'(x) = 2x$. Hence,\n",
    "$$ x_{n+1} = x_{n} - \\frac{x_n^2 - a}{2x_n}.$$\n",
    "As shown in class, Newton's method converges quadratically given a sufficiently smooth function $f$ and $f'(\\sqrt{a}) \\neq 0$. Clearly $f$ is smooth. Since $a>0$ by assumption, we have $f'(\\sqrt{a}) = 2\\sqrt{a} > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B\n",
    "Suppose we have processor with limited functionality. It can compute $+,-,*$, but cannot compute general division $/$. Instead, it can only half a number (i.e., divide by $2$). Follow a similar procedure as in part A to devise a fixed point iteration for computing $x = 1/\\sqrt{a}$. It is then simple to compute $\\sqrt{a}$ by multiplying $1/\\sqrt{a}$ by $a$. (Your iteration should only use $+, -, *$ and division by 2.) Show that the iteration converges quadratically for any $a>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: \n",
    "Let $f(x) = \\frac{1}{x^2} - a$. We have that $f(x) = 0$ implies that $x = \\pm\\frac{1}{\\sqrt{a}}$. We have that $f'(x) = -\\frac{2}{x^3}$. Newton's method is then\n",
    "$$x_{n+1} = x_n - \\frac{\\frac{1}{x_n^2} - a}{-\\frac{2}{x_n^3}} \n",
    "= x_n + \\frac{x_n - ax_n^3}{2}.$$\n",
    "Note that the above uses only the allowed operations operations, $+, -, *$ and division by 2. Our function is smooth in a neighborhood of the root, and since $a > 0$ by assumption, we have that $f'(\\frac{1}{\\sqrt{a}}) > 0$. Hence the iteration will converge quadratically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
